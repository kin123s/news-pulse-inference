version: '3.8'

services:
  # Zookeeper for Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - news-network
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Kafka Broker
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    hostname: kafka
    container_name: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9093,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_LOG_RETENTION_HOURS: 24
      KAFKA_LOG_RETENTION_BYTES: 1073741824  # 1GB
    networks:
      - news-network
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9093"]
      interval: 15s
      timeout: 10s
      retries: 5

  # Redis
  redis:
    image: redis:7-alpine
    hostname: redis
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    networks:
      - news-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Producer Service
  producer:
    build:
      context: .
      dockerfile: Dockerfile.producer
    container_name: news-producer
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8001:8001"
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9093
      KAFKA_TOPIC: news_stream
      NEWS_API_KEY: ${NEWS_API_KEY:-your_api_key_here}
      NEWS_API_URL: https://newsapi.org/v2/top-headlines
      FETCH_INTERVAL: 300  # 5분마다
    networks:
      - news-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Consumer Service
  consumer:
    build:
      context: .
      dockerfile: Dockerfile.consumer
    container_name: news-consumer
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "8002:8002"
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9093
      KAFKA_TOPIC: news_stream
      KAFKA_GROUP_ID: news_consumer_group
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_DB: 0
      CONSUMER_PORT: 8002
    networks:
      - news-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Inference Server (NEW!)
  inference:
    build:
      context: .
      dockerfile: Dockerfile.inference
    container_name: news-inference
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "8000:8000"
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9093
      KAFKA_INPUT_TOPIC: news_stream
      KAFKA_OUTPUT_TOPIC: analyzed_news
      KAFKA_CONSUMER_GROUP: inference_group
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_DB: 0
      MAX_CONCURRENT_REQUESTS: 20
      BATCH_SIZE: 10
      BATCH_TIMEOUT: 2.0
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      HUGGINGFACE_API_KEY: ${HUGGINGFACE_API_KEY:-}
      USE_EXTERNAL_API: ${USE_EXTERNAL_API:-false}
    networks:
      - news-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    # GPU 지원 (선택사항)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  # Faust Stream Processor (선택사항 - Inference에 통합 가능)
  stream-processor:
    build:
      context: .
      dockerfile: Dockerfile.inference
    container_name: faust-stream-processor
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: faust -A inference.stream_processor:NewsStreamProcessor worker -l info
    environment:
      KAFKA_BROKER: kafka://kafka:9093
      INPUT_TOPIC: news_stream
      OUTPUT_TOPIC: analyzed_news
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
    networks:
      - news-network
    restart: unless-stopped

  # Prometheus for monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    networks:
      - news-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    depends_on:
      - prometheus
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=http://localhost:3000
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana-dashboards:/etc/grafana/provisioning/dashboards
    networks:
      - news-network
    restart: unless-stopped

  # Frontend (Vue.js)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: news-frontend
    depends_on:
      - consumer
      - inference
    ports:
      - "80:80"
    environment:
      - VITE_API_BASE_URL=http://localhost:8002
      - VITE_WS_URL=ws://localhost:8002/ws
      - VITE_INFERENCE_URL=http://localhost:8000
    networks:
      - news-network
    restart: unless-stopped

networks:
  news-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.25.0.0/16

volumes:
  redis-data:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local

